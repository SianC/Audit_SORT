{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bebba5d-989b-47d0-9ac4-c32d89da007b",
   "metadata": {},
   "source": [
    "# Fairness Audit Tool\n",
    "\n",
    "\n",
    "#### What do you need?\n",
    " - pandas\n",
    " - os.path\n",
    " - pick_labels (py file)\n",
    " - import_data (py file)\n",
    " \n",
    "\n",
    "#### Data:\n",
    " - Data is in csv format\n",
    " - Columns for ground truth (what is your model aiming to recreate?), model results and protected characteristic you would like to investigate available\n",
    " \n",
    "\n",
    " \n",
    "#### What do you get?\n",
    " - Find out if there is a difference in outcomes for your ground truth, dependent on the protected characteristic. \n",
    " - Find out if there is a difference in statistical parity for your model predictions, dependent on the protected characteristic.\n",
    " - Comparisons are 1-1. For example, if your protected characteristic contains A, B and C, then results will compare A and B; A and C; and B and C.\n",
    " - If you have an expected difference (for example, an illness that men are more likely to get than women), you can find the expected differences you should have, accounting for that.\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ac50c-d993-4645-ad14-cbfdcbc30533",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74760fba-e870-4282-ac75-d3d48163c417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import docs\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import import_data as imd\n",
    "import pick_labels as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6721ed9b-783f-496d-b7a8-44aea894d037",
   "metadata": {},
   "source": [
    "### Load data and pick columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf290ba7-a5ae-4da5-8854-fd03a17b34b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the full location of your data on your device:  D:\\SORT\\Data\\predictions_clinical_only_with_percent_bins_death.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you, this is the first 5 rows of the dataframe you have loaded.\n",
      "   age sex  mort30  phat.clinical  phat.sort_clinical  phat.sort  \\\n",
      "0   32   F   False          0.005            0.002277   0.007290   \n",
      "1   68   F   False          0.005            0.003473   0.015828   \n",
      "2   58   F   False          0.005            0.000870   0.001231   \n",
      "3   66   M   False          0.005            0.001134   0.002009   \n",
      "4   68   M   False          0.005            0.001134   0.002009   \n",
      "\n",
      "  percentage_clin_mort percentage_sort_clin_mort percentage_sort_mort  \\\n",
      "0                  <1%                       <1%                  <1%   \n",
      "1                  <1%                       <1%              1%-2.5%   \n",
      "2                  <1%                       <1%                  <1%   \n",
      "3                  <1%                       <1%                  <1%   \n",
      "4                  <1%                       <1%                  <1%   \n",
      "\n",
      "   pred_death  \n",
      "0       False  \n",
      "1       False  \n",
      "2       False  \n",
      "3       False  \n",
      "4       False  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter the name of the column containing your ground truth:  mort30\n",
      "Please enter the name of the column containing your model results:  pred_death\n",
      "Please enter the name of the name of the column containing the characteristic you would like to audit:  sex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The potential values of your protected characteristic are  ['F', 'M']\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "df = imd.import_data()\n",
    "#Pick requirements\n",
    "ground_truth = pl.ground_truth(df)\n",
    "model_results = pl.model_result(df, ground_truth)\n",
    "protected_chara = pl.protected_chara(df, ground_truth, model_results)\n",
    "#List the potential values for protected characteristic\n",
    "protected_values = list(df[protected_chara].unique())\n",
    "print(\"The potential values of your protected characteristic are \", protected_values)\n",
    "pot_results = list(df[model_result].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1ecc5b-2cc9-47ee-9e18-e8275886d477",
   "metadata": {},
   "source": [
    "### Is there an expected bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f869eae-6d2a-4b66-ae1f-440d94c5db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you expect there to be explainable bias in your data? For example, you may be looking at a disease that has a higher rate in men. (Yes/No) no\n"
     ]
    }
   ],
   "source": [
    "##Find expected bias\n",
    "a=0\n",
    "b=0\n",
    "rate=0\n",
    "while a==0:\n",
    "    while b==0:\n",
    "        expected = input(\"Do you expect there to be explainable bias in your data? For example, you may be looking at a disease that has a higher rate in men. (Yes/No)\")\n",
    "        if expected == \"Yes\" or expected == \"Y\" or expected == \"yes\":\n",
    "            b=1\n",
    "        elif expected == \"No\" or expected == \"N\" or expected == \"no\":\n",
    "            b=1\n",
    "            a=1\n",
    "        else:\n",
    "            print(\"Please answer Yes or No.\")\n",
    "    if a==1:\n",
    "        break\n",
    "    d=0\n",
    "    while d==0:\n",
    "        expected = input(\"Do you know the what the rate of difference is?\")\n",
    "        if expected == \"Yes\" or expected == \"Y\" or expected == \"yes\":\n",
    "            d=1\n",
    "        elif expected == \"No\" or expected == \"N\" or expected == \"no\":\n",
    "            a=1\n",
    "            d=1\n",
    "        else:\n",
    "            print(\"Please answer Yes or No.\")\n",
    "    if a==1:\n",
    "        break\n",
    "    e=0\n",
    "    while e==0:\n",
    "        rate = input(\"Please enter your expected rate. If you do not know the expected rate, please enter 0. For example, if disease is twice as high in men you should enter 2. \")\n",
    "        try:\n",
    "            val = float(rate)\n",
    "            c=0\n",
    "            while c==0:\n",
    "                lean = input(\"Please enter the group that has the higher rate, as it shows in your data\")\n",
    "                if lean not in protected_values:\n",
    "                    print(\"please ensure that your xxx is one of your protected values\")\n",
    "                else:\n",
    "                    print(\"We will take this into consideration\")\n",
    "                    a=1\n",
    "                    e=1\n",
    "                    c=1\n",
    "        except ValueError:\n",
    "            print(\"That's not a float!\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239bdb00-92ec-48e0-a9b4-db147b554547",
   "metadata": {},
   "source": [
    "### Bias in the original data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c25f68-9c16-4c07-b1fc-f8deb389a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is little to no bias in this data\n"
     ]
    }
   ],
   "source": [
    "#Information about data\n",
    "df_info = pd.DataFrame(columns=['Group 1', 'Group 2 ', 'Difference', 'Ground_Truth'])\n",
    "AA = []\n",
    "BB = []\n",
    "CC = []\n",
    "DD = []\n",
    "EE = []\n",
    "a=0\n",
    "b=0\n",
    "#Run through all potential protected values twice to pair up all possibilities\n",
    "for j in range(0,len(protected_values)):\n",
    "    privileged_group = protected_values[j]\n",
    "    for i in range(j,len(protected_values)):\n",
    "        unprivileged_group = protected_values[i]\n",
    "        if unprivileged_group == privileged_group:\n",
    "            cool = \"cool\"\n",
    "        else:\n",
    "            #Split new dataframes for each characteristic\n",
    "            unprivileged_df = df[df[protected_chara] == unprivileged_group]\n",
    "            privileged_df = df[df[protected_chara] == privileged_group]\n",
    "\n",
    "            privileged_df[ground_truth] = privileged_df[ground_truth].astype(str)\n",
    "            unprivileged_df[ground_truth] = unprivileged_df[ground_truth].astype(str)\n",
    "            \n",
    "            #run through all potential results\n",
    "            for k in range(0, len(pot_results)):\n",
    "                percent = pot_results[k]\n",
    "                prob_of_death_unprivileged = len(unprivileged_df[unprivileged_df[ground_truth] == percent])/len(unprivileged_df)\n",
    "                prob_of_death_privileged = len(privileged_df[privileged_df[ground_truth] == percent])/len(privileged_df)\n",
    "                \n",
    "                AA.append(privileged_group)\n",
    "                BB.append(unprivileged_group)\n",
    "                CC.append(prob_of_death_unprivileged - prob_of_death_privileged)\n",
    "                DD.append(percent)\n",
    "\n",
    "                #If there is an expected difference\n",
    "                if rate != 0 and (lean == privileged_group or lean == unprivileged_group):\n",
    "                    \n",
    "                    df_r = df[df[protected_chara] == lean]\n",
    "                    M_t = len(df_r)\n",
    "                    M_d = len(df_r[df_r[ground_truth] == percent])\n",
    "                    if lean == privileged_group:\n",
    "                        Fdf_r = unprivileged_df\n",
    "                    else:\n",
    "                        Fdf_r = privileged_df\n",
    "                    expected_result = M_d/M_t - (M_d/int(rate))/len(Fdf_r)\n",
    "                    EE.append(expected_result)\n",
    "                   \n",
    "df_info['Group 1'] = AA\n",
    "df_info['Group 2'] = BB\n",
    "df_info['Difference'] = CC\n",
    "df_info['Ground_Truth'] = DD\n",
    "if rate != 0 and (lean == privileged_group or lean == unprivileged_group):\n",
    "    df_info['Expected'] = EE \n",
    "    dif = [a_i - b_i for a_i, b_i in zip(CC, EE)]\n",
    "if any(abs(t)>0.1 for t in CC):\n",
    "    if dif:\n",
    "        if any(r>0.1 for r in dif):\n",
    "            print(\"There is some unexpected bias in this data. This is equivalent to...\")\n",
    "        else:\n",
    "            print(\"There is some bias in this data, however it matches with your expected levels.\")\n",
    "    else:\n",
    "        print(\"There is some unexpected bias in this data. This is equivalent to...\")\n",
    "else:\n",
    "    print(\"There is little to no bias in this data\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0816dc-e6c0-407b-baeb-c4830ce13351",
   "metadata": {},
   "source": [
    "The following table contains more information about these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fef4a65-1827-496e-b2a6-3792967693f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Group 1 Group 2   Difference Ground_Truth Group 2\n",
      "0       F      NaN   -0.006108        False       M\n",
      "1       F      NaN    0.006108         True       M\n"
     ]
    }
   ],
   "source": [
    "print(df_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ee2524-e994-404c-8b72-8ae63054980c",
   "metadata": {},
   "source": [
    "### Bias in the model results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aecf2a77-3b17-4a5c-aeba-a6a238213bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is little to no bias in these results\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of model\n",
    "df_sp = pd.DataFrame(columns=['Group 1', 'Group 2', 'Statistical_Parity', 'Model_Result'])\n",
    "FF = []\n",
    "GG = []\n",
    "HH = []\n",
    "II = []\n",
    "JJ = []\n",
    "\n",
    "#Run through protected values twice to pair them all up\n",
    "prob_of_death_list = []\n",
    "for j in range(0,len(protected_values)):\n",
    "    privileged_group = protected_values[j]\n",
    "    for i in range(j,len(protected_values)):\n",
    "        unprivileged_group = protected_values[i]\n",
    "        if unprivileged_group == privileged_group:\n",
    "            cool = \"cool\"\n",
    "        else:\n",
    "            unprivileged_df = df[df[protected_chara] == unprivileged_group]\n",
    "            privileged_df = df[df[protected_chara] == privileged_group]\n",
    "            \n",
    "            #Run through all potential results\n",
    "            for k in range(0, len(pot_results)):\n",
    "                percent = pot_results[k]\n",
    "                prob_of_death_unprivileged = len(unprivileged_df[unprivileged_df[model_result]==percent])/len(unprivileged_df)\n",
    "                prob_of_death_privileged = len(privileged_df[privileged_df[model_result]==percent])/len(privileged_df)\n",
    "                prob_of_death = prob_of_death_unprivileged - prob_of_death_privileged\n",
    "                prob_of_death_list.append([[privileged_group,unprivileged_group], percent, prob_of_death])\n",
    "                FF.append(privileged_group)\n",
    "                GG.append(unprivileged_group)\n",
    "                HH.append(prob_of_death_unprivileged - prob_of_death_privileged)\n",
    "                II.append(percent)\n",
    "                \n",
    "                #If there is an expected difference...\n",
    "                if rate != 0 and (lean == privileged_group or lean == unprivileged_group):\n",
    "                    \n",
    "                    df_r = df[df[protected_chara] == lean]\n",
    "                    M_t = len(df_r)\n",
    "                    M_d = len(df_r[df_r[ground_truth] == percent])\n",
    "                    if lean == privileged_group:\n",
    "                        Fdf_r = unprivileged_df\n",
    "                    else:\n",
    "                        Fdf_r = privileged_df\n",
    "                    expected_result = M_d/M_t - (M_d/int(rate))/len(Fdf_r)\n",
    "                    JJ.append(expected_result)\n",
    "            \n",
    "\n",
    "                \n",
    "df_sp['Group 1'] = FF\n",
    "df_sp['Group 2'] = GG\n",
    "df_sp['Statistical_Parity'] = HH\n",
    "df_sp['Model_Result'] = II\n",
    "if rate != 0 and (lean == privileged_group or lean == unprivileged_group):\n",
    "    df_sp['Expected'] = JJ\n",
    "    dif_2 = [a_i - b_i for a_i, b_i in zip(HH, JJ)]\n",
    "\n",
    "if any(abs(t)>0.1 for t in HH):\n",
    "    if dif:\n",
    "        if any(r>0.1 for r in dif):\n",
    "            print(\"There is some unexpected bias in these results. This is equivalent to...\")\n",
    "        else:\n",
    "            print(\"There is some bias in these results, however it matches with your expected levels.\")\n",
    "    else:\n",
    "        print(\"There is some unexpected bias in these results. This is equivalent to...\")\n",
    "else:\n",
    "    print(\"There is little to no bias in these results\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e170df-f5ad-46dd-a085-52ae287cfb67",
   "metadata": {},
   "source": [
    "The following table contains more information about these results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa03ed58-b80c-4797-8160-72b4d2b7f5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Group 1 Group 2  Statistical_Parity Model_Result\n",
      "0       F       M           -0.011801        False\n",
      "1       F       M            0.011801         True\n"
     ]
    }
   ],
   "source": [
    "print(df_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22ef689-1874-408d-904c-ee5d4298a470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
